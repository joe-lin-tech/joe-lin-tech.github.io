---
layout: page
title: cs180 - introduction to algorithms and complexity
description: course notes from summer '24
related_publications: true
references: notes/cs180.bib
pseudocode: true
tikzjax: true
pretty_table: true
---

## Stable Matching
A common example of a **stable matching** problem is that of marriage, in which we'd like to match $$n$$ men with $$n$$ women based on their preferences. Here, we consider the scenario of med-school student admissions to hospitals. We are given a set of preferences among hospitals and med-school students and we'd like to come up with an algorithm to match students to hospitals.

unstable pair
: hospital $$h$$ and student $$s$$ form an **unstable pair** if both
    - $$h$$ prefers $$s$$ to one of its admitted students
    - $$s$$ prefers $$h$$ to assigned hospital

In other words, an unstable pair occurs when the hospital and student both prefer each other more than their current matching. Given this, we can now define a **stable matching**, which is simply an assignment with no unstable pairs.

matching
: a **matching** $$M$$ is a set of ordered pairs $$h-s$$ with $$h \in H$$ and $$s \in S$$ such that all hospitals and students appear in at most one pair of $$M$$

perfect matching
: a matching M is **perfect** if all hospitals and students are matched

Note that, graphically, we can think of these matchings as a **bipartite graph**.

stable matching
: a **stable matching** is a perfect matching with no unstable pairs

### Gale-Shapley
```pseudocode
\begin{algorithm}
\caption{Gale-Shapley}
\begin{algorithmic}
\STATE{initialize $$M$$ to empty matching}
\WHILE{some hospital $$h$$ is unmatched and hasn't offered to every student}
    \STATE $$s =$$ first student on $$h$$'s list to whom $$h$$ has not yet offered
    \IF{$$s$$ is unmatched}
        \STATE add $$h-s$$ to matching $$M$$
    \ELIF{$$s$$ prefers $$h$$ to current partner $$h'$$}
        \STATE replace $$h'-s$$ with $$h-s$$ in matching $$M$$
    \ELSE
        \STATE $$s$$ rejects $$h$$
    \ENDIF
\ENDWHILE
\end{algorithmic}
\end{algorithm}
```

To prove the correctness of this algorithm, we must show that it (1) terminates, (2) produces a perfect matching, and (3) results in a stable matching.
1. **Claim: Gale-Shapley terminates in at most $$n^2$$ iterations.**
    - By brief inspection, we can prove termination by noticing that the while loop will run at most $$n^2$$ iterations and thus, in total, hospitals make at most $$n^2$$ proposals.
2. **Claim: Gale-Shapley produces a perfect matching.**
    - **Subclaim: Gale-Shapley produces a matching.** Since hospitals only match with the best unmatched student, they are in at most one pair. Since students only keep the best offer, they are also in at most one pair. Because both hospitals and students appear in at most one pair, the algorithm produces a matching.
    - **Subclaim: All hospitals and students are matched.** We can show that all hospitals are matched with a proof by contradiction. Suppose that there exists a hospital $$h$$ that is unmatched at the end of the algorithm. Since there are $$n$$ hospitals and $$n$$ students, an unmatched hospital implies an unmatched student $$s$$. This means that $$s$$ was never given an offer. However, $$h$$ must have offered to all $$n$$ students. Thus, by contradiction, all hospitals are matched. It follows that if all hospitals are matched and every hospital is matched to at most one student, then all students are matched.
    - Since Gale-Shapley produces a matching and all hospitals and students are matched, we can conclude that it produces a perfect matching.
3. **Claim: Gale-Shapley produces a stable matching.**
    - We can prove this by contradiction. Suppose the matching $$M$$ from Gale-Shapley is not stable, meaning that there exists an unstable pair $$h-s$$. We know that $$h$$ prefers $$s$$ over $$s'$$ and $$s$$ prefers $$h$$ over $$h'$$, where $$s'$$ and $$h'$$ are their current matches in $$M$$. There are two cases for which this could occur.
        - **Case 1:** $$h$$ never offers to $$s$$ and $$h$$ ends up offering to $$s'$$ in $$M$$. However, since $$h$$ offers in order of preference, this would imply that $$h$$ prefers $$s'$$ over $$s$$ and hence we have a contradiction.
        - **Case 2:** $$h$$ offers to $$s$$, but $$s$$ rejects $$h$$ for $$h'$$. However, this means that $$s$$ prefers $$h'$$ over $$h$$ and hence we have a contradiction.
    - By contradiction, we have proven that the Gale-Shapley matching $$M$$ does not have an unstable pair and thus produces a stable matching.

valid partner
: a student $$s$$ is a **valid partner** of $$h$$ if there exists any stable matching with $$h-s$$

**Claim: Gale-Shapley is hospital-optimal.**

## Proof Techniques
### Loop Invariants
loop invariant
: a **loop invariant** is a condition that must be true before entering the loop, after each iteration, and after the loop has completed

### Induction
**Claim: Any $$2n \times 2n$$ board with any square removed can be tiled with L-shaped tiles for any $$n$$ greater than or equal to $$1$$.**

We can prove this with induction.
- **Base Case:** For $$n = 1$$, we have a $$2 \times 2$$ board. By inspection, we can see that regardless of which square we remove, we can tile the remaining squares with an L-shaped tile. The four cases are shown below, in which the green square is removed and the blue squares are covered by the L-shaped tile.

<div align="center" class="pb-4">
    <div class="d-flex flex-wrap flex-md-row flex-column justify-content-between align-items-center w-50">
        <script type="text/tikz">
        \begin{tikzpicture}
            \draw[green, fill=black!60!green] (-1, 1) rectangle (0, 0);
            \draw[blue, fill=black!60!blue] (1, 1) rectangle (0, 0);
            \draw[blue, fill=black!60!blue] (-1, -1) rectangle (0, 0);
            \draw[blue, fill=black!60!blue] (1, -1) rectangle (0, 0);
        \end{tikzpicture}
        </script>
        <script type="text/tikz">
        \begin{tikzpicture}
            \draw[blue, fill=black!60!blue] (-1, 1) rectangle (0, 0);
            \draw[green, fill=black!60!green] (1, 1) rectangle (0, 0);
            \draw[blue, fill=black!60!blue] (-1, -1) rectangle (0, 0);
            \draw[blue, fill=black!60!blue] (1, -1) rectangle (0, 0);
        \end{tikzpicture}
        </script>
        <script type="text/tikz">
        \begin{tikzpicture}
            \draw[blue, fill=black!60!blue] (-1, 1) rectangle (0, 0);
            \draw[blue, fill=black!60!blue] (1, 1) rectangle (0, 0);
            \draw[green, fill=black!60!green] (-1, -1) rectangle (0, 0);
            \draw[blue, fill=black!60!blue] (1, -1) rectangle (0, 0);
        \end{tikzpicture}
        </script>
        <script type="text/tikz">
        \begin{tikzpicture}
            \draw[blue, fill=black!60!blue] (-1, 1) rectangle (0, 0);
            \draw[blue, fill=black!60!blue] (1, 1) rectangle (0, 0);
            \draw[blue, fill=black!60!blue] (-1, -1) rectangle (0, 0);
            \draw[green, fill=black!60!green] (1, -1) rectangle (0, 0);
        \end{tikzpicture}
        </script>
    </div>
</div>

- **Inductive Hypothesis:** Suppose that a $$2n \times 2n$$ board with any square removed can be tiled with L-shaped tiles for some $$n \geq 1$$.
- **Inductive Step:** For the $$n + 1$$ case, we have a $$2^{n + 1} \times 2^{n + 1}$$ board, which we can split into four $$2^n \times 2^n$$ quadrants. Now, remove any square we'd like. The quadrant that this removed square sits in is now a $$2^n \times 2^n$$ board with one square removed. For the remaining quadrants, we can place an L-shaped tile at the center of the $$2^{n + 1} \times 2^{n + 1}$$ board, which essentially also turns the $$3$$ quadrants into $$2^n \times 2^n$$ boards with one square removed. By the inductive hypothesis, we can now tile all of these quadrants with L-shaped tiles. The $$n = 2$$ case is shown below, in which the green square is removed, the yellow squares are covered by $$1$$ L-shaped tile that we place, and the blue squares are covered by L-shaped tiles placed as a result of our inductive hypothesis.

<div align="center" class="pb-4">
    <div class="d-flex flex-wrap flex-md-row flex-column justify-content-center align-items-center w-75">
        <script type="text/tikz">
        \begin{tikzpicture}
            \draw[green, fill=black!60!green] (-2, 2) rectangle (-1, 1);
            \draw[blue, fill=black!60!blue] (-1, 1) -- (-1, 2) -- (0, 2) -- (0, 0) -- (-2, 0) -- (-2, 1) -- cycle;
            \draw[blue, fill=black!60!blue] (-2, -2) -- (-2, 0) -- (-1, 0) -- (-1, -1) -- (0, -1) -- (0, -2) -- cycle;
            \draw[blue, fill=black!60!blue] (2, -2) -- (0, -2) -- (0, -1) -- (1, -1) -- (1, 0) -- (2, 0) -- cycle;
            \draw[blue, fill=black!60!blue] (2, 2) -- (2, 0) -- (1, 0) -- (1, 1) -- (0, 1) -- (0, 2) -- cycle;
            \draw[red, fill=black!60!red] (-1, 0) -- (-1, -1) -- (1, -1) -- (1, 1) -- (0, 1) -- (0, 0) -- cycle;
        \end{tikzpicture}
        </script>
    </div>
</div>

## Asymptotic Notation
big-o
: $$O(g(n))$$ is the set of all functions $$f(n)$$ such that there exists positive constants $$c$$ and $$n_0$$, where for any $$n \geq n_0$$, we have $$0 \leq f(n) \leq c \cdot g(n)$$

Equivalently, $$f(n) \in O(g(n))$$ if and only if $$\lim_{n \rightarrow \infty} \frac{f(n)}{g(n)} \lt \infty$$.

big-omega
: $$\Omega(g(n))$$ is the set of all functions $$f(n)$$ such that there exists positive constants $$c$$ and $$n_0$$, where for any $$n \geq n_0$$, we have $$0 \leq c \cdot g(n) \leq f(n)$$

We can also use the limit rule definition, which says $$f(n) \in \Omega(g(n))$$ if and only if $$\lim_{n \rightarrow \infty} \frac{f(n)}{g(n)} > 0$$.

big-theta
: $$\Theta(g(n))$$ is the set of all functions $$f(n)$$ such that there exists positive constants $$c_1, c_2$$ and $$n_0$$, where for any $$n \geq n_0$$, we have $$0 \leq c_1 \cdot g(n) \leq f(n) \leq c_n \cdot g(n)$$

The limit rule definition tells us that $$f(n) \in \Theta(g(n))$$ if and only if $$\lim_{n \rightarrow \infty} \frac{f(n)}{g(n)} = k$$ for some positive constant $$k$$.

A general **hierarchy of functions** exists: constant &rarr; logarithmic &rarr; polynomial &rarr; exponential. When ordering functions, we can first identify which broad category they belong to and then order each class of functions. For instance, we want to rank the following functions: $$\log{n^n}, n^2, 2^{\log{n}}, \log^2n, n^n, n^{\log{n}}, 2^n, 2^{1000}, n^{\sqrt{2}}$$.

| Constant | Logarithmic | Polynomial | Exponential |
| :------- | :---------- | :--------- | :---------- |
| $$2^{1000}$$ | $$\log^2n$$ | $$\log{n^n} = n\log{n}, n^2, 2^{\log{n}} = n, n^{\sqrt{2}}$$ | $$n^n, n^{\log{n}}, 2^n$$ |

For the polynomial functions, we immediately know that $$n \lt n^{\sqrt{2}} \lt n^2$$. For $$n\log{n}$$, we can factor out $$n$$ from all $$4$$ functions and since we know that constant $$\lt$$ logarithmic $$\lt$$ polynomial functions, then the final ordering is $$n \lt n\log{n} \lt n^{\sqrt{2}} \lt n^2$$.

For the exponential functions, we can compare them by taking the $$\log$$ of every function. We can do this because $$\log$$ is an order-preserving function. So, we get $$n\log{n}, \log^2n, n$$. We can easily order these functions and get $$n^{\log{n}} \lt 2^n \lt n^n$$.

So, the overall ordering of functions is $$2^{1000} \lt \log^2n \lt 2^{\log{n}} \lt \log{n^n} \lt n^{\sqrt{2}} \lt n^2 \lt n^{\log{n}} \lt 2^n \lt n^n$$.

### Properties
$$O, \Omega, \Theta$$ are all **reflexive** [$$f(n) \in O(f(n))$$] and **transitive** [if $$f(n) \in O(g(n))$$ and $$g(n) \in O(h(n))$$, then $$f(n) \in O(h(n))$$]. $$\Theta$$ is also **symmetric** [if $$f(n) \in \Theta(g(n))$$, then $$g(n) \in \Theta(f(n))$$].

Let $$f(n)$$ and $$g(n)$$ be non-negative functions. We want to prove that $$O(f(n) + g(n)) = O(\max(f(n), g(n)))$$. To show that two sets are equal, we must show that both are subsets of one another.
1. **Claim: If $$h(n) \in O(f(n) + g(n))$$, then $$h(n) \in O(\max(f(n), g(n)))$$.**
    - Using the formal definition, we know that there exists a positive $$c, n_0$$ where for any $$n > n_0$$, we have $$0 \leq h(n) \leq c \cdot (f(n) + g(n))$$. Since $$f(n) + g(n) \leq 2 \cdot \max(f(n), g(n))$$, it follows that $$0 \leq h(n) \leq 2c \cdot \max(f(n), g(n))$$. Let $$c' = 2c, n' = n_0$$, then by the formal definition, we can conclude that $$h(n) \in O(\max(f(n), g(n)))$$.
2. **Claim: If $$h(n) \in O(\max(f(n), g(n)))$$, then $$h(n) \in O(f(n) + g(n))$$.**
    - The formal definition tells us that there exists a positive $$c, n_0$$ where for any $$n > n_0$$, we have $$0 \leq h(n) \leq c \cdot \max(f(n), g(n))$$. Since $$\max(f(n), g(n)) \leq f(n) + g(n)$$, it follows that $$0 \leq h(n) \leq c \cdot f(n) + g(n)$$. Let $$c' = c, n' = n_0$$, then by the formal definition, we can conclude that $$h(n) \in O(f(n) + g(n))$$.

Since we've proven both are subsets of one another, we can conclude that $$O(f(n) + g(n)) = O(\max(f(n), g(n)))$$.

To conduct **runtime analysis**, we can follow these steps:
1. Given an algorithm and input of size $$n$$, express the runtime as a function of $$n$$, $$T(n)$$.
2. Derive a closed form expression for $$T(n)$$ if necessary.
3. Apply asymptotic notation to $$T(n)$$ to obtain its order of growth.

```py
def shrinking_array_max(a: List[int]):
    l = len(a) # c_1
    while l >= 1:
        print(max(a[:l])) # c_4 (n / 2^i)
        l /= 2 # c_2
        if l < 1: # c_3
            break
    return
```
For the above function, we can see that it consists of constant time operations $$c_1, c_2, c_3$$ inside and outside of the while loop as well as a linear-time <code>max</code> operation. It's important to note that because $$l$$ is halved at every iteration, the size of the input array for <code>max</code> is also halved. It follows that the runtime for the max operation is actually $$c_4 \cdot \frac{n}{2^i}$$, where $$i$$ corresponds to the number of times $$l$$ has been halved. We know that the number of times $$n$$ can be halved is $$\log{n}$$. So, in summary, we have the following:

$$ \begin{aligned} T(n) &= c_1 + \sum_{i = 0}^{\log{n}} (c_2 + c_3 + c_4 \frac{n}{2^i}) \\
&= c_1 + \sum_{i = 0}^{\log{n}} (c_5 + c_4 \frac{n}{2^i}) \\
&= c_6 + c_5 \log{n} + \sum_{i = 0}^{\log{n}} c_4 \frac{n}{2^i} \\
&< c_6 + c_5 \log{n} + c_4 n \sum_{i = 0}^\infty \frac{1}{2^i} \\
&= c_6 + c_5 \log{n} + 2 c_4 n \end{aligned} $$

Now, we can apply asymptotic notation, giving us $$T(n) = O(n)$$.

## Graphs
graph
: a **graph** $$G = (V, E)$$ is a collection of **vertices** $$V$$ of size $$n$$ and **edges** $$E$$ of size $$m$$

degree
: in an **undirected graph**, the **degree** of a vertex is the number of edges for which it is an endpoint

**Claim: The sum of degrees of all vertices in a graph is twice the number of edges.**
We can prove this with a loop invariant, where after $$i$$ iterations, the sum of degrees for all vertices is $$2i$$.

### Graph Representation
adjacency matrix
: an **adjacency matrix** is a $$n \times n$$ matrix $$A$$ where $$A_{u, v} = 1$$ if $$(u, v)$$ is an edge

An adjacency matrix has two representations for each edge of an undirected graph ($$A_{u, v} = A_{v, u}$$). Its spatial complexity is proportional to $$n^2$$. We can check if $$(u, v)$$ is an edge in $$\Theta(1)$$ time, but iterating through all the edges takes $$\Theta(n^2)$$ time.

adjacency list
: an **adjacency list** is a node-indexed array of lists

An adjacency list also has two representations for each edge, but only requires $$\Theta(m + n)$$ space. We can check if $$(u, v)$$ is an edge in $$O(degree(u))$$ time and identify all edges in $$\Theta(m + n)$$ time.

path
: a **path** in an undirected graph $$G = (V, E)$$ is a sequence of nodes $$v_1, v_2, ..., v_k$$ where each consecutive pair $$v_{i - 1}, v_i$$ is joined by an edge $$(v_{i - 1}, v_i) \in E$$

We say that a graph is **connected** if there exists a path between every pair of nodes $$u$$ and $$v$$.

cycle
: a **cycle** is a path $$v_1, v_2, ..., v_k$$ in which $$v_1 = v_k$$ and $$k ≥ 2$$

tree
: an undirected graph is a **tree** if it is connected and does not contain a cycle

**Claim: A tree on $$n$$ vertices has exactly $$n - 1$$ edges for all $$n$$ greater than or equal to $$1$$.**
We can prove this with induction.
- **Base Case:** For $$n = 1$$, the tree has $$n - 1 = 0$$ edges.
- **Inductive Hypothesis:** Suppose that a tree on $$n$$ vertices has exactly $$n - 1$$ edges for some $$n \geq 1$$.
- **Inductive Step:** Then, for the $$n + 1$$ case, we want to show that a tree $$T$$ on $$n + 1$$ vertices has exactly $$n$$ edges. Let us pick a leaf node $$v$$, which is a vertex with degree $$1$$. If we remove $$v$$ and the edge $$e$$ that connects it to the rest of the tree, we obtain a graph $$T'$$ with $$n$$ vertices. We know that $$T'$$ is also a tree because removing an edge and vertex doesn't create a cycle and $$T'$$ is trivially connected. Since $$T'$$ is a tree on $$n$$ vertices, then by the inductive hypothesis, $$T'$$ has exactly $$n - 1$$ edges. Now, we readd the $$v$$ and $$e$$ from before to obtain $$T$$. So, $$T$$ has $$(n - 1) + 1 = n$$ edges and we have proven the $$n + 1$$ case.

Thus, by induction we have shown that a tree on $$n$$ vertices has exactly $$n - 1$$ edges for all $$n$$ greater than or equal to $$1$$.

**Claim: Let $$G$$ be an undirected graph on $$n$$ nodes. Then, any two of the following implies the third: (1) $$G$$ is connected, (2) $$G$$ does not contain a cycle, (3) $$G$$ has $$n – 1$$ edges.**

### Graph Traversals
breadth first search
: a **breadth first search** explores the graph from the starting node $$s$$ in all possible directions and finds nodes level by level

```pseudocode
\begin{algorithm}
\caption{Breadth First Search}
\begin{algorithmic}
\STATE mark $$s$$ as visited and the rest unvisited
\STATE set level[0] = \{s\} and i = 0
\WHILE{level[i] is not empty}
    \STATE initialize level[i + 1] as an empty list
    \FOR{vertices $$u$$ in level[i]}
        \FOR{neighbors $$v$$ of $$u$$}
            \IF{$$v$$ has not been visited}
                \STATE mark $$v$$ as visited
                \STATE add $$v$$ to level[i + 1]
            \ENDIF
        \ENDFOR
    \ENDFOR
    \STATE increment $$i$$
\ENDWHILE
\end{algorithmic}
\end{algorithm}
```

Breadth first search runs in $$O(m + n)$$ time. We can arrive at this fact by observing that the outer <code>for</code> loop will execute $$n$$ times, since each vertex appears in only one level and the inner <code>for</code> loop will execute $$2m$$ times, since $$\sum_{v \in V} degree(v) = 2m$$.

depth first search
: a **depth first search** explores the graph in one direction as far as possible before backtracking

```pseudocode
\begin{algorithm}
\caption{Depth First Search}
\begin{algorithmic}
\STATE mark all nodes as unvisited
\STATE initialize stack to only contain $$s$$
\WHILE{stack is not empty}
    \STATE pop from the stack to obtain $$u$$
    \IF{$$u$$ has not been discovered}
        \STATE mark $$u$$ as discovered
        \FOR{neighbors $$v$$ of $$u$$}
            \STATE push $$v$$ onto stack
        \ENDFOR
    \ENDIF
\ENDWHILE
\end{algorithmic}
\end{algorithm}
```

Depth first search also runs in $$O(m + n)$$ time.

connected component
: the **connected component** of $$s$$ are all the nodes reachable from $$s$$

To do graph induction proofs, we can use the following template:
1. Start from $$G$$ that satisfies the premise.
2. Perform graph operations on $$G$$ and obtain $$G'$$ such that the premise of the inductive hypothesis holds for $$G'$$.
3. By the inductive hypothesis, the claim holds for $$G'$$.
4. Reconstruct $$G$$ from $$G'$$ and show that the claim also holds for $$G$$.

bipartite
: a graph is **bipartite** if its vertices can be partitioned into two sets $$L$$ and $$R$$ such that (1) $$L \cup R = V$$, (2) $$L \cap R = \emptyset$$, (3) every edge has one end in $$L$$ and the other in $$R$$

We can also show that a graph is bipartite if and only if it is two-**colorable** and contains no odd length cycles.

**Claim: A graph is bipartite if and only if it is two-colorable.**
- (&rarr;) We want to prove that if a graph is bipartite, then it is two-colorable. We know that $$V$$ can be partitioned into $$L$$ and $$R$$, which we can color blue and green, respectively. Since all edges $$e \in E$$ have one end in $$L$$ and the other in $$R$$, then all edges are not monochromatic and thus we can conclude that the graph is two-colorable.
- (&larr;) We want to prove that if a graph is two-colorable, then it is bipartite. Without loss of generality, we can assign $$L$$ to be blue vertices and $$R$$ to be green vertices. Since there are no monochromatic edges, all edges have one end in $$L$$ and the other in $$R$$ and thus we can conclude that the graph is bipartite.

**Claim: A graph is bipartite if and only if it does not contain an odd length cycle.**
- (&rarr;) We want to prove that if a graph is bipartite, then it does not contain an odd length cycle. By our previous result, $$G$$ is also two-colorable. Now, suppose we have a $$k$$-length cycle in $$G$$, $$(v_0, v_1, ..., v_k)$$. Let's color the vertices at even indices blue and at odd indices green. Since this is a cycle, $$v_0 = v_k$$ and they must have the same color. $$v_0$$ is colored blue, so $$v_k$$ must also be blue, which implies that $$k$$ is even. Thus, for any arbitrary cycle in $$G$$, it must be of even length.
- (&larr;) We want to prove that if a graph does not contain an odd length cycle, then it is bipartite. Let's pick an arbitrary $$v \in V$$ and use breadth first search to partition the vertices into $$L$$ and $$R$$ according to the evenness of their distance from $$v$$. A vertex is in $$L$$ if the distance is even, otherwise it is in $$R$$. Now color vertices in $$L$$ blue and vertices in $$R$$ green. We want to show that no monochromatic edge exists and we can do so by contradiction. Suppose a monochromatic edge $$e = (u', v')$$ does exist. Without loss of generality, let $$u', v' \in L$$, then both are even distances away from $$v$$. If we connect the path from $$u'$$ to $$v$$, the path from $$v'$$ to $$v$$, and $$e$$, we obtain an odd length cycle. However, this contradicts our original assumption and so we have shown that such a monochromatic edge could not exist. Thus, $$G$$ is bipartite.

strong connectivity
: a graph is **strongly connected** if there exists a path from $$u$$ to $$v$$ and $$v$$ to $$u$$ for every pair of nodes $$u, v$$

directed acyclic graphs
: a **directed acyclic graph** or **DAG** is a directed graph that contains no directed cycle

topological order
: a **topological order** of a directed graph $$G = (V, E)$$ is an ordering of its nodes $$v_1, v_2, ..., v_n$$ such that for every edge $$(v_i, v_j)$$ in $$G$$, we have $$i < j$$

**Claim: If $$G$$ has a topological order, then $$G$$ is a DAG.**
We can prove this by contradiction. Suppose $$G$$ has a topological order $$v_1, v_2, ..., v_i, ..., v_j, ..., v_n$$, but $$G$$ is not a DAG. This means that there exists some directed cycle $$(v_i, ..., v_j, v_i)$$ for some $$i < j$$. However, we have an edge $$(v_j, v_i)$$, where $$j > i$$. Thus, we have contradicted one of the criteria of a topological order and so we can conclude that $$G$$ has to be a DAG.

**Claim: If $$G$$ is a DAG, then $$G$$ has a topological ordering.**

