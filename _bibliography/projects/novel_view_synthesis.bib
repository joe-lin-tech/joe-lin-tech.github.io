---
---

@string{aps = {American Physical Society,}}

@inbook{lightfieldrendering,
  author = {Levoy, Marc and Hanrahan, Pat},
  title = {Light Field Rendering},
  year = {2023},
  isbn = {9798400708978},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  edition = {1},
  url = {https://doi.org/10.1145/3596711.3596759},
  abstract = {A number of techniques have been proposed for flying through scenes by redisplaying previously rendered or digitized views. Techniques have also been proposed for interpolating between views by warping input images, using depth information or correspondences between multiple images. In this paper, we describe a simple and robust method for generating new views from arbitrary camera positions without depth information or feature matching, simply by combining and resampling the available images. The key to this technique lies in interpreting the input images as 2D slices of a 4D function - the light field. This function completely characterizes the flow of light through unobstructed space in a static scene with fixed illumination.We describe a sampled representation for light fields that allows for both efficient creation and display of inward and outward looking views. We have created light fields from large arrays of both rendered and digitized images. The latter are acquired using a video camera mounted on a computer-controlled gantry. Once a light field has been created, new views may be constructed in real time by extracting slices in appropriate directions. Since the success of the method depends on having a high sample rate, we describe a compression system that is able to compress the light fields we have generated by more than a factor of 100:1 with very little loss of fidelity. We also address the issues of antialiasing during creation, and resampling during slice extraction.},
  booktitle = {Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
  articleno = {47},
  numpages = {12}
}

@inproceedings{mildenhall2020nerf,
  title = {NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
  author = {Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
  year = {2020},
  booktitle = {ECCV},
}

@misc{nerfmetrics,
  author = {Michael Rubloff},
  title = {What are the NeRF metrics?},
  year = {2023},
  url = {https://radiancefields.com/what-are-the-nerf-metrics/}
}

@misc{intro3dgs,
  author = {Dylan Ebert},
  title = {Introduction to 3D Gaussian Splatting},
  year = {2023},
  url = {https://huggingface.co/blog/gaussian-splatting}
}

@article{kerbl3Dgaussians,
  author = {Kerbl, Bernhard and Kopanas, Georgios and Leimk{\"u}hler, Thomas and Drettakis, George},
  title = {3D Gaussian Splatting for Real-Time Radiance Field Rendering},
  journal = {ACM Transactions on Graphics},
  number = {4},
  volume = {42},
  month = {July},
  year = {2023},
  url = {https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/}
}

@article{structuralsimilarity,
  author = {Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
  journal = {IEEE Transactions on Image Processing}, 
  title = {Image quality assessment: from error visibility to structural similarity}, 
  year = {2004},
  volume = {13},
  number = {4},
  pages = {600-612},
  keywords = {Image quality;Humans;Transform coding;Visual system;Visual perception;Data mining;Layout;Quality assessment;Degradation;Indexes},
  doi = {10.1109/TIP.2003.819861}
}

@misc{hugging3dgs,
  author = {Camen Duru},
  title = {Gaussian Splatting},
  year = {2023},
  url = {https://huggingface.co/camenduru/gaussian-splatting}
}

@misc{splat,
  author = {Kevin Kwok},
  title = {splat.},
  year = {2024},
  url = {https://github.com/antimatter15/splat}
}

@misc{lee2024compact3dgaussianrepresentation,
  title = {Compact 3D Gaussian Representation for Radiance Field}, 
  author = {Joo Chan Lee and Daniel Rho and Xiangyu Sun and Jong Hwan Ko and Eunbyung Park},
  year = {2024},
  eprint = {2311.13681},
  archivePrefix = {arXiv},
  primaryClass = {cs.CV},
  url = {https://arxiv.org/abs/2311.13681}, 
}