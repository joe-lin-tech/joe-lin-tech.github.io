<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> cs188 - deep learning for computer vision | Joe Lin </title> <meta name="author" content="Joe Lin"> <meta name="description" content="course notes from winter '24"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="/assets/libs/mdb/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="/assets/libs/google_fonts/google-fonts.css"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer rel="stylesheet" href="/assets/libs/pseudocode/pseudocode.min.css" integrity="sha256-VwMV//xgBPDyRFVSOshhRhzJRDyBmIACniLPpeXNUdc=" crossorigin="anonymous"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://joe-lin-tech.github.io/notes/cs188/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <link defer rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Joe</span> Lin </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item active"> <a class="nav-link" href="/notes/">notes <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">cs188 - deep learning for computer vision</h1> <p class="post-description">course notes from winter '24</p> </header> <article> <h2 id="image-classification">Image Classification</h2> <p>As humans, we find it relatively easy to reason about what we see an image. For a computer, however, all it sees is a matrix of numbers, which presents an inherent <strong>semantic gap</strong> between reality and its numerical representation.</p> <dl> <dt>image classification</dt> <dd>a core computer vision task that assigns a semantic label to an input image</dd> </dl> <p>We can immediately identify some of the primary challenges of image classification:</p> <ul> <li> <strong>viewpoint variation:</strong> raw pixel values can change significantly just by varying viewing direction of the same object</li> <li> <strong>intraclass variation:</strong> there are oftentimes many variations of the same class of objects (e.g. multitude of chair designs)</li> <li> <strong>fine-graind categories:</strong> equally challenging is to identify specific subclasses</li> <li> <strong>context:</strong> occlusion, non-canonical views, scene clutter</li> <li> <strong>domain changes:</strong> visual styles (e.g. painting, clip art, photo)</li> </ul> <p>As you might imagine, image classification is an essential building block for accomplishing other downstream vision tasks like object detection, image captioning, semantic segmentation, and others.</p> <dl> <dt>mnist</dt> <dd>a \(28 \times 28\) grayscale handwritten digit dataset with \(10\) classes (one for each digit), \(50k\) training images, and \(10k\) test images</dd> <dt>cifar-10</dt> <dd>a \(32 \times 32\) RGB image dataset with \(10\) classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck), \(50k\) training images (\(5k\) per class), \(10k\) test images (\(1k\) per class)</dd> <dt>places</dt> <dd>a variable size image dataset covering \(365\) scene classes with \(1.8M\) training images on the standard set \(8M\) training images on the challenge set, \(18.25k\) validation images (\(50\) per class), and \(328.5K\) test images (\(900\) per class)</dd> </dl> <h3 id="nearest-neighbors">Nearest Neighbors</h3> <dl> <dt>nearest neighbors</dt> <dd>memorize all the training images and at test time predict the label of the closest image using a predefined distance metric</dd> </dl> <p>The distance metric quantifies the similarity between two images. Some common metrics include the <strong>manhattan distance</strong> (i.e. <strong>\(\mathcal{l}_1\)-norm</strong>) and the <strong>euclidean distance</strong> (i.e. <strong>\(\mathcal{l}_2\)-norm</strong>). We can visualize the difference in these metrics below.</p> <div align="center" class="pb-4"> <div class="d-flex flex-wrap flex-md-row flex-column justify-content-between align-items-center w-50"> <script type="text/tikz">
        \begin{tikzpicture}
            \draw[white, fill=black] (-2, 2) rectangle (-1, 1);
            \draw[white, fill=black] (-2, 1) rectangle (-1, 0);
            \draw[white, fill=black] (-2, 0) rectangle (-1, -1);
            \draw[white, fill=black] (-2, -1) rectangle (-1, -2);
            \draw[white, fill=black] (-1, 2) rectangle (0, 1);
            \draw[white, fill=black] (-1, 1) rectangle (0, 0);
            \draw[white, fill=black] (-1, 0) rectangle (0, -1);
            \draw[white, fill=black] (-1, -1) rectangle (0, -2);
            \draw[white, fill=black] (0, 2) rectangle (1, 1);
            \draw[white, fill=black] (0, 1) rectangle (1, 0);
            \draw[white, fill=black] (0, 0) rectangle (1, -1);
            \draw[white, fill=black] (0, -1) rectangle (1, -2);
            \draw[white, fill=black] (1, 2) rectangle (2, 1);
            \draw[white, fill=black] (1, 1) rectangle (2, 0);
            \draw[white, fill=black] (1, 0) rectangle (2, -1);
            \draw[white, fill=black] (1, -1) rectangle (2, -2);
            \filldraw[green] (-2, -2) circle (2pt);
            \filldraw[yellow] (2, 2) circle (2pt);
            \draw[red] (-2, -2) -- (-1, -2) -- (-1, -1) -- (0, -1) -- (0, 0) -- (1, 0) -- (1, 1) -- (2, 1) -- (2, 2);
        \end{tikzpicture}
        </script> <script type="text/tikz">
        \begin{tikzpicture}
            \draw[white, fill=black] (-2, 2) rectangle (-1, 1);
            \draw[white, fill=black] (-2, 1) rectangle (-1, 0);
            \draw[white, fill=black] (-2, 0) rectangle (-1, -1);
            \draw[white, fill=black] (-2, -1) rectangle (-1, -2);
            \draw[white, fill=black] (-1, 2) rectangle (0, 1);
            \draw[white, fill=black] (-1, 1) rectangle (0, 0);
            \draw[white, fill=black] (-1, 0) rectangle (0, -1);
            \draw[white, fill=black] (-1, -1) rectangle (0, -2);
            \draw[white, fill=black] (0, 2) rectangle (1, 1);
            \draw[white, fill=black] (0, 1) rectangle (1, 0);
            \draw[white, fill=black] (0, 0) rectangle (1, -1);
            \draw[white, fill=black] (0, -1) rectangle (1, -2);
            \draw[white, fill=black] (1, 2) rectangle (2, 1);
            \draw[white, fill=black] (1, 1) rectangle (2, 0);
            \draw[white, fill=black] (1, 0) rectangle (2, -1);
            \draw[white, fill=black] (1, -1) rectangle (2, -2);
            \filldraw[green] (-2, -2) circle (2pt);
            \filldraw[yellow] (2, 2) circle (2pt);
            \draw[red] (-2, -2) -- (2, 2);
        \end{tikzpicture}
        </script> </div> </div> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="k">class</span> <span class="nc">NearestNeighbor</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Train nearest neighbor classifier by memorizing training data.
        
        Args:
            x (np.array) - N x D matrix of input images
            y (np.array) - N corresponding labels
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">x_train</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">self</span><span class="p">.</span><span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Make predictions based on the label of the nearest neighbor.

        Args:
            x (np.array) - N x D matrix of input images

        Returns:
            y_pred (np.array) - N predicted labels
        </span><span class="sh">"""</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">y_train</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">x_train</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">y_train</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmin</span><span class="p">(</span><span class="n">dist</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">y_pred</span>
</code></pre></div></div> <p>A key observation is that the training time is \(O(1)\), while inference time is \(O(n)\). This is quite undesirable. We almost always want the opposite (i.e. long training and fast inference).</p> <p>We can also extend this logic to <strong>\(k\)-nearest neighbors</strong>, where we take a majority vote of their labels.</p> <p><em>How do we select the best \(k\) and distance metric to use?</em> To do so, we can follow a standard machine learning framework. We can split our dataset into a <strong>train</strong> set, <strong>validation</strong> set, and <strong>test</strong> set. We train our algorithm on the train set, tune for hyperparameters with the validation set, and save the test set for final evaluation. For smaller datasets, we can further improve this with <strong>\(k\)-fold cross validation</strong>, in which we split the data into folds, try each fold as validation, and average the results.</p> <h3 id="linear-classifier">Linear Classifier</h3> <dl> <dt>linear classifier</dt> <dd>learn a set of weights \(W \in \mathbb{R}^{C \times D}\) and biases \(b \in \mathbb{R}^{C}\) such that \(f(x, W) = x W^T + b\) for \(x \in \mathbb{R}^{N \times D}\), where \(D\) is the input dimension and \(C\) is the number of output classes</dd> </dl> <p>In our case, we’d like our input \(x\) to be an image and the output to be the corresponding scene type, either living room, highway, or mountain. Recall that a RGB image can be represented by an \(H \times W \times 3\) matrix, where \(H\) is the image height and \(W\) is the image width. To use a linear classifier, we want to first flatten each of our \(N\) images into a \(1\)-dimensional vector of size \(H \cdot W \cdot 3\). It follows that the input dimension is \(D = H \times W \times 3\) and since there are \(3\) types of scenes, the output dimension is \(C = 3\).</p> <p>Let’s suppose we have \(N = 1, H = 5\), and \(W = 5\).</p> <div align="center" class="pb-4"> <div class="d-flex flex-wrap flex-column align-items-center"> <script type="text/tikz">
        \usetikzlibrary{decorations.pathreplacing}
        \begin{tikzpicture}
            \definecolor{goldenrod}{RGB}{247, 207, 91}
            \definecolor{coral}{RGB}{216, 100, 85}
            \definecolor{slategray}{RGB}{53, 55, 52}
            \definecolor{gray}{RGB}{49, 48, 49}
            \draw[white, fill=gray] (0, 0) rectangle (1, -1);
            \draw[white, fill=goldenrod] (0, -1) rectangle (1, -2);
            \draw[white, fill=white] (0, -2) rectangle (1, -3);
            \draw[white, fill=goldenrod] (0, -3) rectangle (1, -4);
            \draw[white, fill=white] (0, -4) rectangle (1, -5);
            \draw[white, fill=white] (1, 0) rectangle (2, -1);
            \draw[white, fill=slategray] (1, -1) rectangle (2, -2);
            \draw[white, fill=coral] (1, -2) rectangle (2, -3);
            \draw[white, fill=goldenrod] (1, -3) rectangle (2, -4);
            \draw[white, fill=goldenrod] (1, -4) rectangle (2, -5);
            \draw[white, fill=white] (2, 0) rectangle (3, -1);
            \draw[white, fill=goldenrod] (2, -1) rectangle (3, -2);
            \draw[white, fill=goldenrod] (2, -2) rectangle (3, -3);
            \draw[white, fill=goldenrod] (2, -3) rectangle (3, -4);
            \draw[white, fill=white] (2, -4) rectangle (3, -5);
            \draw[white, fill=white] (3, 0) rectangle (4, -1);
            \draw[white, fill=slategray] (3, -1) rectangle (4, -2);
            \draw[white, fill=coral] (3, -2) rectangle (4, -3);
            \draw[white, fill=goldenrod] (3, -3) rectangle (4, -4);
            \draw[white, fill=goldenrod] (3, -4) rectangle (4, -5);
            \draw[white, fill=gray] (4, 0) rectangle (5, -1);
            \draw[white, fill=goldenrod] (4, -1) rectangle (5, -2);
            \draw[white, fill=white] (4, -2) rectangle (5, -3);
            \draw[white, fill=goldenrod] (4, -3) rectangle (5, -4);
            \draw[white, fill=white] (4, -4) rectangle (5, -5);
            %\draw[white, fill=gray] (7, 3.5) rectangle (8, 2.5);
            %\draw[white, fill=white] (7, 2.5) rectangle (8, 1.5);
            \draw[white, fill=gray] (7, 1.5) rectangle (8, 0.5);
            \draw[white, fill=white] (7, 0.5) rectangle (8, -0.5);
            \draw[white, fill=white] (7, -0.5) rectangle (8, -1.5);
            \draw[white, fill=gray!10] (7.5, -2) circle (1pt);
            \draw[white, fill=gray!10] (7.5, -2.5) circle (1pt);
            \draw[white, fill=gray!10] (7.5, -3) circle (1pt);
            \draw[white, fill=white] (7, -3.5) rectangle (8, -4.5);
            \draw[white, fill=goldenrod] (7, -4.5) rectangle (8, -5.5);
            \draw[white, fill=white] (7, -5.5) rectangle (8, -6.5);
            %\draw[white, fill=goldenrod] (7, -6.5) rectangle (8, -7.5);
            %\draw[white, fill=white] (7, -7.5) rectangle (8, -8.5);
            \node[text=black, fill=white, rounded corners=.1cm] at (2.5, -2.5) {RGB Image $\in \mathbb{R}^{1 \times \!5 \times \!5 \times \!3}$};
            \node[text=black, fill=white, rounded corners=.1cm] at (7.5, -2.5) {$x \in \mathbb{R}^{1 \times \!75}$};
        \end{tikzpicture}
        </script> </div> </div> <div align="center" class="pb-4"> <div class="d-flex flex-wrap flex-column align-items-center"> <script type="text/tikz">
        \usetikzlibrary{decorations.pathreplacing}
        \begin{tikzpicture}
            \definecolor{gray}{RGB}{49, 48, 49}
            \draw[white, fill=gray] (0, -1) rectangle (1, -1);
            \draw[white, fill=gray] (1, -1) rectangle (2, -1);
            \draw[white, fill=gray] (2, -1) rectangle (3, -1);
            \draw[white, fill=gray] (4, -1) rectangle (5, -2);
            \draw[white, fill=gray] (4, -2) rectangle (5, -3);
            \draw[white, fill=gray] (4, -3) rectangle (5, -4);
            \draw[white, fill=gray] (5, -1) rectangle (6, -2);
            \draw[white, fill=gray] (5, -2) rectangle (6, -3);
            \draw[white, fill=gray] (5, -3) rectangle (6, -4);
            \draw[white, fill=gray] (6, -1) rectangle (7, -2);
            \draw[white, fill=gray] (6, -2) rectangle (7, -3);
            \draw[white, fill=gray] (6, -3) rectangle (7, -4);
            \draw[white, fill=gray] (7, -1) rectangle (8, -2);
            \draw[white, fill=gray] (7, -2) rectangle (8, -3);
            \draw[white, fill=gray] (7, -3) rectangle (8, -4);
            \draw[white, fill=gray] (8, -1) rectangle (9, -2);
            \draw[white, fill=gray] (8, -2) rectangle (9, -3);
            \draw[white, fill=gray] (8, -3) rectangle (9, -4);
            \draw[white, fill=gray] (9, -1) rectangle (10, -2);
            \draw[white, fill=gray] (9, -2) rectangle (10, -3);
            \draw[white, fill=gray] (9, -3) rectangle (10, -4);
            \node[text=black, fill=white, rounded corners=.1cm] at (1.5, -0.5) {$x \in \mathbb{R}^{1 \times \!75}$};
            \node[text=black, fill=white, rounded corners=.1cm] at (7, -1.5) {$W^T \in \mathbb{R}^{75 \times \!3}$};
            \% draw arrow here *\
        \end{tikzpicture}
        </script> </div> </div> </article> <h2>References</h2> <div class="publications"> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Joe Lin. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="/assets/libs/jquery/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="/assets/libs/mdb/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="/assets/libs/masonry/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="/assets/libs/imagesloaded/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> <script defer src="/assets/libs/medium_zoom/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0}};</script> <script type="text/javascript" id="MathJax-script" src="/assets/libs/mathjax/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script type="text/javascript" src="/assets/libs/pseudocode/pseudocode.min.js" integrity="sha256-aVkDxqyzrB+ExUsOY9PdyelkDhn/DfrjWu08aVpqNlo=" crossorigin="anonymous"></script> <script>document.addEventListener("readystatechange",()=>{"complete"===document.readyState&&document.querySelectorAll("pre>code.language-pseudocode").forEach(e=>{const t=e.textContent,d=e.parentElement.parentElement;let n=document.createElement("pre");n.classList.add("pseudocode");const o=document.createTextNode(t);n.appendChild(o),d.appendChild(n),d.removeChild(e.parentElement),pseudocode.renderElement(n)})});</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"recent research works",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"a collection of academic and extracurricular projects in machine learning and web development!",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-notes",title:"notes",description:"collection of detailed notes and summaries from my academic courses",section:"Navigation",handler:()=>{window.location.href="/notes/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-digital-humans",title:"digital humans",description:"a deep dive into representing and understanding humans",section:"Posts",handler:()=>{window.location.href="/blog/2024/digital-humans/"}},{id:"news-lt-strong-gt-learning-to-generate-diverse-pedestrian-movements-from-web-videos-with-noisy-labels-lt-strong-gt-is-accepted-to-lt-em-gt-iclr-2025-lt-em-gt",title:"&lt;strong&gt;Learning to Generate Diverse Pedestrian Movements from Web Videos with Noisy Labels&lt;/strong&gt; is accepted to &lt;em&gt;ICLR 2025&lt;/em&gt;.",description:"",section:"News"},{id:"news-lt-strong-gt-learning-assistant-lt-strong-gt-for-prof-bolei-zhou-s-cs-163",title:"&lt;strong&gt;Learning Assistant&lt;/strong&gt; for Prof. Bolei Zhou\u2019s CS 163!",description:"",section:"News"},{id:"news-joined-zhou-lab-at-ucla",title:"Joined Zhou Lab at UCLA.",description:"",section:"News"},{id:"notes-cs180-introduction-to-algorithms-and-complexity",title:"cs180 - introduction to algorithms and complexity",description:"course notes from summer &#39;24",section:"Notes",handler:()=>{window.location.href="/notes/cs180/"}},{id:"notes-cs188-deep-learning-for-computer-vision",title:"cs188 - deep learning for computer vision",description:"course notes from winter &#39;24",section:"Notes",handler:()=>{window.location.href="/notes/cs188/"}},{id:"projects-cifar-image-classification",title:"cifar image classification",description:"using popular deep learning architectures",section:"Projects",handler:()=>{window.location.href="/projects/cifar/"}},{id:"projects-autonomous-vehicle-expo",title:"autonomous vehicle expo",description:"eagle project conference website",section:"Projects",handler:()=>{window.location.href="/projects/conference/"}},{id:"projects-novel-view-synthesis",title:"novel view synthesis",description:"com sci 188 final project (w/ michael song and alexander chien)",section:"Projects",handler:()=>{window.location.href="/projects/novel_view_synthesis/"}},{id:"projects-abdominal-trauma-detection",title:"abdominal trauma detection",description:"rsna kaggle competition",section:"Projects",handler:()=>{window.location.href="/projects/rsna_atd/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6A%6F%65%6C%69%6E%74%65%63%68@%75%63%6C%61.%65%64%75","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/joe-lin-tech","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/joe-lin-tech","_blank")}},{id:"socials-kaggle",title:"Kaggle",section:"Socials",handler:()=>{window.open("https://www.kaggle.com/16385395","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>